{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import spotipy.util as util\n",
    "import pandas as pd\n",
    "import re\n",
    "from time import sleep\n",
    "from random import random\n",
    "from time import time\n",
    "import glob\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Credentials\n",
    "with open('SpotifyID.txt', 'r') as f:\n",
    "    client_id = f.read().replace('\\n','')\n",
    "with open('SpotifySecret.txt', 'r') as f:\n",
    "    client_secret = f.read().replace('\\n','')\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "sp.trace=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token(client_seccret,client_id):\n",
    "    AUTH_URL = 'https://accounts.spotify.com/api/token'\n",
    "\n",
    "    # POST\n",
    "    auth_response = requests.post(AUTH_URL, {\n",
    "        'grant_type': 'client_credentials',\n",
    "        'client_id': client_id,\n",
    "        'client_secret': client_secret,\n",
    "    })\n",
    "\n",
    "    # convert the response to JSON\n",
    "    auth_response_data = auth_response.json()\n",
    "\n",
    "    # save the access token\n",
    "    access_token = auth_response_data['access_token']\n",
    "    \n",
    "    return access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_analysis(track_id,access_token):\n",
    "    \n",
    "    headers = {\n",
    "    'Authorization': 'Bearer {token}'.format(token=access_token)\n",
    "    }\n",
    "\n",
    "    track_id = track_id.split(\":\")[-1]\n",
    "    # base URL of all Spotify API endpoints\n",
    "    BASE_URL = 'https://api.spotify.com/v1/'\n",
    "    \n",
    "    # actual GET request with proper header\n",
    "    return(requests.get(BASE_URL + 'audio-features/' + track_id, headers=headers).json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(data_cleaned,file_loc):\n",
    "    count=0\n",
    "    uris, dates, popularities, audio_analysis=[],[],[],[]\n",
    "    access_token = get_token(client_secret,client_id)\n",
    "    for i in range(0,len(data_cleaned)):  \n",
    "        #query artist and song\n",
    "        artist=str(data_cleaned.loc[i,\"artist\"])\n",
    "        title=str(data_cleaned.loc[i,\"song\"])\n",
    "\n",
    "        #some songs have many artists associated\n",
    "        #however spotify only lists few, so break the string into parts \n",
    "        #and search till match is found\n",
    "        artist.replace(\",\",\" \")\n",
    "        artist_string = [artist] + artist.strip().split()\n",
    "        for artist in artist_string:\n",
    "            if len(artist)>2:\n",
    "                search_query = str(title) + ' ' + str(artist)\n",
    "                result = sp.search(search_query)\n",
    "                if result[\"tracks\"][\"items\"]!=[]:\n",
    "                    break\n",
    "        \n",
    "        if result[\"tracks\"][\"items\"]==[]:\n",
    "            uris.append(\"error\")\n",
    "            dates.append(\"error\")\n",
    "            popularities.append(\"error\")\n",
    "            audio_analysis.append({\"error\":\"\"})   \n",
    "            print(\"error\",count,title,artist_string)\n",
    "            count+=1\n",
    "        \n",
    "        else:\n",
    "            print(i,result[\"tracks\"][\"items\"][0][\"uri\"],artist)\n",
    "            audio = get_audio_analysis(result[\"tracks\"][\"items\"][0][\"uri\"],access_token)\n",
    "            uri=result[\"tracks\"][\"items\"][0][\"uri\"]\n",
    "            date= result[\"tracks\"][\"items\"][0][\"album\"][\"release_date\"]\n",
    "            popularity = result[\"tracks\"][\"items\"][0][\"popularity\"]  \n",
    "\n",
    "            uris.append(uri)\n",
    "            dates.append(date)\n",
    "            popularities.append(popularity)\n",
    "            audio_analysis.append(audio)\n",
    "\n",
    "    return uris, dates, popularities, audio_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(uris, dates, popularities, audio_analysis, data_cleaned, file_loc):\n",
    "    data_cleaned[\"uris\"] = uris\n",
    "    data_cleaned[\"popularity\"] = popularities\n",
    "    data_cleaned[\"date\"] = dates\n",
    "    \n",
    "    \n",
    "    temp = pd.DataFrame({\"audio\":audio_analysis})\n",
    "    audio_analysis = pd.json_normalize(temp[\"audio\"])\n",
    "    data_cleaned = pd.concat([data_cleaned,audio_analysis],axis =1)\n",
    "    data_cleaned.to_csv(file_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in songs from main df\n",
    "datasets = glob.glob(\"./songs_wikipedia/*.csv\")\n",
    "datasets2 = glob.glob(\"./songs_wikipedia_final/*.csv\")\n",
    "for file_loc in datasets:\n",
    "    data_cleaned = pd.read_csv(file_loc)\n",
    "    for column in data_cleaned.columns:\n",
    "        #data_cleaned[column] = data_cleaned[column].str.strip()\n",
    "        data_cleaned = data_cleaned.dropna(subset =[\"song\"]).reset_index(drop =True)\n",
    "    file_loc = file_loc.replace(\"songs_wikipedia\",\"songs_wikipedia_final\")\n",
    "    if file_loc not in datasets2:\n",
    "        print(file_loc)\n",
    "        uris, dates, popularities, audio_analysis = query(data_cleaned,file_loc)\n",
    "        create_csv(uris, dates, popularities, audio_analysis, data_cleaned, file_loc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "['song']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-341-b0b80dd8c582>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_cleaned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m#data_cleaned[column] = data_cleaned[column].str.strip()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mdata_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_cleaned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"song\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mfile_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_loc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"songs_wikipedia\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"songs_wikipedia_final\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile_loc\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdropna\u001b[0;34m(self, axis, how, thresh, subset, inplace)\u001b[0m\n\u001b[1;32m   4746\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4747\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4748\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4749\u001b[0m             \u001b[0magg_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ['song']"
     ]
    }
   ],
   "source": [
    "datasets = glob.glob(\"./songs_lyrics/*.csv\")\n",
    "datasets2 = glob.glob(\"./songs_lyrics_final/*.csv\")\n",
    "for file_loc in datasets:\n",
    "    data_cleaned = pd.read_csv(file_loc)\n",
    "    for column in data_cleaned.columns:\n",
    "        #data_cleaned[column] = data_cleaned[column].str.strip()\n",
    "        data_cleaned = data_cleaned.dropna(subset =[\"song\"]).reset_index(drop =True)\n",
    "    file_loc = file_loc.replace(\"songs_wikipedia\",\"songs_wikipedia_final\")\n",
    "    if file_loc not in datasets2:\n",
    "        print(file_loc)\n",
    "        uris, dates, popularities, audio_analysis = query(data_cleaned,file_loc)\n",
    "        create_csv(uris, dates, popularities, audio_analysis, data_cleaned, file_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_city</th>\n",
       "      <th>song_state</th>\n",
       "      <th>song_artist</th>\n",
       "      <th>song_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Jamie Foxx</td>\n",
       "      <td>Georgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Field Mob</td>\n",
       "      <td>Georgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Lil Wayne</td>\n",
       "      <td>Georgia... Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Count Basie</td>\n",
       "      <td>Sweet Georgia Brown [DVD]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>The Coasters</td>\n",
       "      <td>Sweet Georgia Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4636</th>\n",
       "      <td>Savannah</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>State Radio</td>\n",
       "      <td>State of Georgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4637</th>\n",
       "      <td>Savannah</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Crooked I</td>\n",
       "      <td>Apex Predator (My Gun Go)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4638</th>\n",
       "      <td>Savannah</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Client Liaison</td>\n",
       "      <td>Wild Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4639</th>\n",
       "      <td>Savannah</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>La Dispute</td>\n",
       "      <td>VIEW FROM OUR BEDROOM WINDOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4640</th>\n",
       "      <td>Savannah</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Tec</td>\n",
       "      <td>Up Next</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4641 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     song_city song_state     song_artist                     song_name\n",
       "0      Georgia    Georgia      Jamie Foxx                       Georgia\n",
       "1      Georgia    Georgia       Field Mob                       Georgia\n",
       "2      Georgia    Georgia       Lil Wayne               Georgia... Bush\n",
       "3      Georgia    Georgia     Count Basie     Sweet Georgia Brown [DVD]\n",
       "4      Georgia    Georgia    The Coasters           Sweet Georgia Brown\n",
       "...        ...        ...             ...                           ...\n",
       "4636  Savannah    Georgia     State Radio              State of Georgia\n",
       "4637  Savannah    Georgia       Crooked I     Apex Predator (My Gun Go)\n",
       "4638  Savannah    Georgia  Client Liaison                     Wild Life\n",
       "4639  Savannah    Georgia      La Dispute  VIEW FROM OUR BEDROOM WINDOW\n",
       "4640  Savannah    Georgia             Tec                       Up Next\n",
       "\n",
       "[4641 rows x 4 columns]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"./songs_lyrics/Georgia.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
