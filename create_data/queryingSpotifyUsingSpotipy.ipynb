{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import spotipy.util as util\n",
    "import pandas as pd\n",
    "import re\n",
    "from time import sleep\n",
    "from random import random\n",
    "from time import time\n",
    "import glob\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Credentials\n",
    "with open('SpotifyID.txt', 'r') as f:\n",
    "    client_id = f.read().replace('\\n','')\n",
    "with open('SpotifySecret.txt', 'r') as f:\n",
    "    client_secret = f.read().replace('\\n','')\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "sp.trace=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token(client_seccret,client_id):\n",
    "    AUTH_URL = 'https://accounts.spotify.com/api/token'\n",
    "\n",
    "    # POST\n",
    "    auth_response = requests.post(AUTH_URL, {\n",
    "        'grant_type': 'client_credentials',\n",
    "        'client_id': client_id,\n",
    "        'client_secret': client_secret,\n",
    "    })\n",
    "\n",
    "    # convert the response to JSON\n",
    "    auth_response_data = auth_response.json()\n",
    "\n",
    "    # save the access token\n",
    "    access_token = auth_response_data['access_token']\n",
    "    \n",
    "    return access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_analysis(track_id,access_token):\n",
    "    \n",
    "    headers = {\n",
    "    'Authorization': 'Bearer {token}'.format(token=access_token)\n",
    "    }\n",
    "\n",
    "    track_id = track_id.split(\":\")[-1]\n",
    "    # base URL of all Spotify API endpoints\n",
    "    BASE_URL = 'https://api.spotify.com/v1/'\n",
    "    \n",
    "    # actual GET request with proper header\n",
    "    return(requests.get(BASE_URL + 'audio-features/' + track_id, headers=headers).json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(data_cleaned,file_loc):\n",
    "    count=0\n",
    "    uris, dates, popularities, audio_analysis=[],[],[],[]\n",
    "    access_token = get_token(client_secret,client_id)\n",
    "    for i in range(0,len(data_cleaned)):  \n",
    "        #query artist and song\n",
    "        artist=str(data_cleaned.loc[i,\"artist\"])\n",
    "        title=str(data_cleaned.loc[i,\"song\"])\n",
    "\n",
    "        #some songs have many artists associated\n",
    "        #however spotify only lists few, so break the string into parts \n",
    "        #and search till match is found\n",
    "        artist.replace(\",\",\" \")\n",
    "        artist_string = [artist] + artist.strip().split()\n",
    "        for artist in artist_string:\n",
    "            if len(artist)>2:\n",
    "                search_query = str(title) + ' ' + str(artist)\n",
    "                result = sp.search(search_query)\n",
    "                if result[\"tracks\"][\"items\"]!=[]:\n",
    "                    break\n",
    "        \n",
    "        if result[\"tracks\"][\"items\"]==[]:\n",
    "            uris.append(\"error\")\n",
    "            dates.append(\"error\")\n",
    "            popularities.append(\"error\")\n",
    "            audio_analysis.append({\"error\":\"\"})   \n",
    "            print(\"error\",count,title,artist_string)\n",
    "            count+=1\n",
    "        \n",
    "        else:\n",
    "            print(i,result[\"tracks\"][\"items\"][0][\"uri\"],artist)\n",
    "            audio = get_audio_analysis(result[\"tracks\"][\"items\"][0][\"uri\"],access_token)\n",
    "            uri=result[\"tracks\"][\"items\"][0][\"uri\"]\n",
    "            date= result[\"tracks\"][\"items\"][0][\"album\"][\"release_date\"]\n",
    "            popularity = result[\"tracks\"][\"items\"][0][\"popularity\"]  \n",
    "\n",
    "            uris.append(uri)\n",
    "            dates.append(date)\n",
    "            popularities.append(popularity)\n",
    "            audio_analysis.append(audio)\n",
    "\n",
    "    return uris, dates, popularities, audio_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(uris, dates, popularities, audio_analysis, data_cleaned, file_loc):\n",
    "    data_cleaned[\"uris\"] = uris\n",
    "    data_cleaned[\"popularity\"] = popularities\n",
    "    data_cleaned[\"date\"] = dates\n",
    "    \n",
    "    \n",
    "    temp = pd.DataFrame({\"audio\":audio_analysis})\n",
    "    audio_analysis = pd.json_normalize(temp[\"audio\"])\n",
    "    data_cleaned = pd.concat([data_cleaned,audio_analysis],axis =1)\n",
    "    data_cleaned.to_csv(file_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in songs from main df\n",
    "datasets = glob.glob(\"./songs_wikipedia/*.csv\")\n",
    "datasets2 = glob.glob(\"./songs_wikipedia_final/*.csv\")\n",
    "for file_loc in datasets:\n",
    "    data_cleaned = pd.read_csv(file_loc)\n",
    "    for column in data_cleaned.columns:\n",
    "        #data_cleaned[column] = data_cleaned[column].str.strip()\n",
    "        data_cleaned = data_cleaned.dropna(subset =[\"song\"]).reset_index(drop =True)\n",
    "    file_loc = file_loc.replace(\"songs_wikipedia\",\"songs_wikipedia_final\")\n",
    "    if file_loc not in datasets2:\n",
    "        print(file_loc)\n",
    "        uris, dates, popularities, audio_analysis = query(data_cleaned,file_loc)\n",
    "        create_csv(uris, dates, popularities, audio_analysis, data_cleaned, file_loc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = glob.glob(\"./songs_lyrics/*.csv\")\n",
    "datasets2 = glob.glob(\"./songs_lyrics_final/*.csv\")\n",
    "for file_loc in datasets:\n",
    "    data_cleaned = pd.read_csv(file_loc)\n",
    "    for column in data_cleaned.columns:\n",
    "        #data_cleaned[column] = data_cleaned[column].str.strip()\n",
    "        data_cleaned = data_cleaned.dropna(subset =[\"song\"]).reset_index(drop =True)\n",
    "    file_loc = file_loc.replace(\"songs_lyrics\",\"songs_lyrics_final\")\n",
    "    if file_loc not in datasets2:\n",
    "        print(file_loc)\n",
    "        uris, dates, popularities, audio_analysis = query(data_cleaned,file_loc)\n",
    "        create_csv(uris, dates, popularities, audio_analysis, data_cleaned, file_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"./songs_lyrics/Georgia.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = pd.read_csv(\"./songs_lyrics/Alabama.csv\")\n",
    "for column in data_cleaned.columns:\n",
    "    #data_cleaned[column] = data_cleaned[column].str.strip()\n",
    "    data_cleaned = data_cleaned.dropna(subset =[\"song\"]).reset_index(drop =True)\n",
    "uris, dates, popularities, audio_analysis = query(data_cleaned,\"./songs_lyrics_final/ Alabama.csv\")\n",
    "create_csv(uris, dates, popularities, audio_analysis, data_cleaned, \"./songs_lyrics_final/ Alabama.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
