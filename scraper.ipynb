{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The goal of this script is to scrape various sites to create a dataframe of songs of various cities in the United States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Wikipedia (https://en.wikipedia.org/wiki/List_of_songs_about_cities#United_States)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get(\"https://en.wikipedia.org/wiki/List_of_songs_about_cities#United_States\")\n",
    "html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "h3s = html_soup.find_all(\"h3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = []\n",
    "songs =[]\n",
    "for i in range(348,497):\n",
    "    places.append(h3s[i].text)\n",
    "    songs.append(h3s[i].findNext(\"ul\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"places\":places,\"songs\":songs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"city\",\"state\"]]=data[\"places\"].str.split(\",\",expand = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (data\n",
    " .set_index([\"city\",\"state\"])\n",
    " .songs.str.split(\"\\n\",expand = True)\n",
    " .stack()\n",
    " .reset_index()\n",
    " .rename(columns={0:'songs'})\n",
    " .loc[:,[\"city\",\"state\",\"songs\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"state\"] = data[\"state\"].str.split(\"[\",expand = True).iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Wikipedia page, there are some cities which have so many songs that they have their own separate wikipages\n",
    "The webscraper does not capture this, we need to manually get these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Cheyenne</td>\n",
       "      <td>Wyoming[edit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California[edit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California[edit]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            city              state\n",
       "92      Cheyenne      Wyoming[edit]\n",
       "299  Los Angeles   California[edit]\n",
       "298  Los Angeles   California[edit]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.duplicated([\"songs\"],keep=\"last\")][[\"city\",\"state\"]].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets drop these for now and maybe scrape them separately later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = data.drop_duplicates(\"songs\",keep=\"last\").reset_index(drop =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Texas             86\n",
       " New Mexico        54\n",
       " Oklahoma          33\n",
       " Tennessee         33\n",
       " Ohio              33\n",
       " Pennsylvania      32\n",
       " Missouri          27\n",
       " California        25\n",
       " Nevada            24\n",
       " Maryland          24\n",
       " Minnesota         24\n",
       " Arizona           15\n",
       " Florida           14\n",
       " Virginia          12\n",
       " D.C.              11\n",
       " Colorado          10\n",
       " Kansas            10\n",
       " Michigan           9\n",
       " Wyoming            9\n",
       " Nebraska           8\n",
       " Alabama            8\n",
       " Georgia            7\n",
       " South Carolina     7\n",
       " New Jersey         6\n",
       " Illinois           6\n",
       " Arkansas           5\n",
       " Indiana            5\n",
       " North Carolina     5\n",
       " Kentucky           4\n",
       " Mississippi        4\n",
       " Washington         4\n",
       " Idaho              4\n",
       " Iowa               4\n",
       " Louisiana          3\n",
       " Wisconsin          3\n",
       " Maine              3\n",
       " Alaska             3\n",
       " New York           3\n",
       " Utah               2\n",
       " Oregon             2\n",
       " Hawaii             2\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned[\"state\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-236-8cdfcf698d75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_cleaned\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"songs.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "pd.to_csv(data_cleaned,\"songs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
